"""
Integration tests for Intelligent Fallback System.

This module tests the complete intelligent fallback system in realistic scenarios,
demonstrating the robustness of the Playwright â†’ requests fallback strategy.

These tests use real network calls to validate the system works end-to-end.
"""

import pytest

from src.scraper.application.contracts.browser_automation import BrowserConfiguration
from src.scraper.infrastructure.web_scraping.fallback_browser_automation import (
    FallbackBrowserFactory,
)
from src.scraper.infrastructure.web_scraping.intelligent_fallback_scraper import (
    FallbackConfig,
    FallbackStrategy,
    IntelligentFallbackScraper,
)


class TestIntelligentFallbackIntegration:
    """Integration tests for the intelligent fallback system."""

    @pytest.fixture
    def optimized_config(self):
        """Configuration optimized for testing."""
        return FallbackConfig(
            playwright_timeout=10,  # Shorter for testing
            requests_timeout=5,
            max_retries=2,
            circuit_breaker_threshold=3,
            enable_resource_blocking=True,
            blocked_resource_types=["image", "stylesheet", "font", "media"],
        )

    @pytest.fixture
    def scraper(self, optimized_config):
        """Configured intelligent scraper for testing."""
        return IntelligentFallbackScraper(config=optimized_config)

    @pytest.mark.asyncio
    @pytest.mark.integration
    async def test_successful_requests_fallback_httpbin(self, scraper):
        """Test successful scraping using httpbin.org (may use Playwright or fallback)."""
        result = await scraper.scrape_url("https://httpbin.org/html")

        assert result.success is True
        # Either strategy is acceptable - the system chooses the best one
        assert result.strategy_used in [
            FallbackStrategy.PLAYWRIGHT_OPTIMIZED,
            FallbackStrategy.REQUESTS_FALLBACK,
        ]
        assert result.attempts >= 1
        assert "html" in result.content.lower()
        assert result.performance_metrics is not None
        assert result.performance_metrics["total_time"] > 0

    @pytest.mark.asyncio
    @pytest.mark.integration
    async def test_resource_blocking_performance_benefit(self):
        """Test that resource blocking configuration works correctly."""
        # Test with resource blocking enabled
        config_with_blocking = FallbackConfig(
            enable_resource_blocking=True,
            blocked_resource_types=["image", "stylesheet", "font", "media"],
            playwright_timeout=15,
        )
        scraper_with_blocking = IntelligentFallbackScraper(config_with_blocking)

        # Test with resource blocking disabled
        config_without_blocking = FallbackConfig(
            enable_resource_blocking=False,
            playwright_timeout=15,
        )
        scraper_without_blocking = IntelligentFallbackScraper(config_without_blocking)

        # Use a simple page for testing
        test_url = "https://httpbin.org/html"

        result_with_blocking = await scraper_with_blocking.scrape_url(test_url)
        result_without_blocking = await scraper_without_blocking.scrape_url(test_url)

        assert result_with_blocking.success is True
        assert result_without_blocking.success is True

        # Both should succeed with any strategy
        assert result_with_blocking.strategy_used in [
            FallbackStrategy.PLAYWRIGHT_OPTIMIZED,
            FallbackStrategy.REQUESTS_FALLBACK,
        ]
        assert result_without_blocking.strategy_used in [
            FallbackStrategy.PLAYWRIGHT_OPTIMIZED,
            FallbackStrategy.REQUESTS_FALLBACK,
        ]

    @pytest.mark.asyncio
    @pytest.mark.integration
    async def test_circuit_breaker_prevents_repeated_failures(self):
        """Test circuit breaker functionality with successful requests."""
        config = FallbackConfig(
            circuit_breaker_threshold=5,  # Higher threshold for real testing
            playwright_timeout=10,
            requests_timeout=10,
        )
        scraper = IntelligentFallbackScraper(config)

        # Make multiple successful requests to test circuit breaker doesn't interfere
        results = []
        for i in range(3):
            result = await scraper.scrape_url("https://example.com")
            results.append(result)

        # All should succeed
        for result in results:
            assert result.success is True
            assert result.strategy_used in [
                FallbackStrategy.PLAYWRIGHT_OPTIMIZED,
                FallbackStrategy.REQUESTS_FALLBACK,
            ]

    @pytest.mark.asyncio
    @pytest.mark.integration
    async def test_custom_headers_in_fallback_mode(self, scraper):
        """Test custom headers functionality."""
        custom_headers = {
            "X-Test-Header": "integration-test",
            "User-Agent": "IntegrationTestBot/1.0",
        }

        result = await scraper.scrape_url(
            "https://httpbin.org/headers", custom_headers=custom_headers
        )

        assert result.success is True
        assert result.strategy_used in [
            FallbackStrategy.PLAYWRIGHT_OPTIMIZED,
            FallbackStrategy.REQUESTS_FALLBACK,
        ]

        # httpbin.org/headers returns the headers that were sent
        # Note: Custom headers may be handled differently by Playwright vs requests
        assert "headers" in result.content.lower()

    @pytest.mark.asyncio
    @pytest.mark.integration
    async def test_content_cleaning_removes_unwanted_elements(self, scraper):
        """Test that content cleaning removes unwanted HTML elements."""
        # Use httpbin which returns clean HTML
        result = await scraper.scrape_url("https://httpbin.org/html")

        assert result.success is True

        # Verify unwanted elements are removed
        assert "<script>" not in result.content
        assert "<style>" not in result.content

        # But content should still be present
        assert "html" in result.content.lower()


class TestFallbackBrowserIntegration:
    """Integration tests for the fallback browser automation adapter."""

    @pytest.fixture
    def browser_config(self):
        """Browser configuration for testing."""
        return BrowserConfiguration(
            user_agent="Mozilla/5.0 (compatible; IntegrationTest/1.0)",
            timeout_seconds=10,
            viewport={"width": 1920, "height": 1080},
        )

    @pytest.fixture
    def browser_factory(self):
        """Factory for creating fallback browsers."""
        return FallbackBrowserFactory()

    @pytest.mark.asyncio
    @pytest.mark.integration
    async def test_fallback_browser_navigation_success(
        self, browser_factory, browser_config
    ):
        """Test successful navigation with fallback browser."""
        fallback_browser = await browser_factory.create_browser(browser_config)
        try:
            response = await fallback_browser.navigate_to_url(
                "https://httpbin.org/html"
            )

            assert response.success is True
            assert response.status_code == 200
            assert response.url == "https://httpbin.org/html"
            assert "html" in response.content.lower()
        finally:
            await fallback_browser.close()

    @pytest.mark.asyncio
    @pytest.mark.integration
    async def test_fallback_browser_content_caching(
        self, browser_factory, browser_config
    ):
        """Test that fallback browser caches content correctly."""
        fallback_browser = await browser_factory.create_browser(browser_config)
        try:
            # Navigate to cache content
            response = await fallback_browser.navigate_to_url(
                "https://httpbin.org/html"
            )
            assert response.success is True

            # Get cached content
            cached_content = await fallback_browser.get_page_content()
            assert cached_content == response.content
            assert "html" in cached_content.lower()
        finally:
            await fallback_browser.close()

    @pytest.mark.asyncio
    @pytest.mark.integration
    async def test_fallback_browser_performance_metrics(
        self, browser_factory, browser_config
    ):
        """Test that performance metrics are collected correctly."""
        fallback_browser = await browser_factory.create_browser(browser_config)
        try:
            response = await fallback_browser.navigate_to_url(
                "https://httpbin.org/html"
            )
            assert response.success is True

            # Check performance metrics
            metrics = fallback_browser.get_last_performance_metrics()
            assert metrics is not None
            assert "total_time" in metrics
            assert metrics["total_time"] > 0
        finally:
            await fallback_browser.close()

    @pytest.mark.asyncio
    @pytest.mark.integration
    async def test_fallback_browser_custom_headers(
        self, browser_factory, browser_config
    ):
        """Test custom headers functionality."""
        fallback_browser = await browser_factory.create_browser(browser_config)
        try:
            custom_headers = {"X-Integration-Test": "fallback-browser"}

            # Set custom headers
            fallback_browser.set_custom_headers(custom_headers)

            response = await fallback_browser.navigate_to_url(
                "https://httpbin.org/headers"
            )

            assert response.success is True
            assert "headers" in response.content.lower()
            # Note: Custom headers may be handled differently by different strategies
        finally:
            await fallback_browser.close()

    @pytest.mark.asyncio
    @pytest.mark.integration
    async def test_fallback_browser_interface_compatibility(
        self, browser_factory, browser_config
    ):
        """Test that fallback browser is compatible with existing interface."""
        from src.scraper.application.contracts.browser_automation import (
            BrowserAutomationInterface,
        )

        fallback_browser = await browser_factory.create_browser(browser_config)
        try:
            # Verify it implements the interface correctly
            assert isinstance(fallback_browser, BrowserAutomationInterface)

            # Test all interface methods work
            stabilized = await fallback_browser.wait_for_content_stabilization(5)
            assert stabilized is True

            click_result = await fallback_browser.click_element("button")
            assert click_result is False  # Expected for fallback mode
        finally:
            # Cleanup should work without errors
            await fallback_browser.close()


class TestEndToEndScenarios:
    """End-to-end tests for realistic scraping scenarios."""

    @pytest.mark.asyncio
    @pytest.mark.integration
    async def test_wikipedia_fallback_scenario(self):
        """Test robust scraping with fallback capabilities."""
        config = FallbackConfig(
            playwright_timeout=10,
            requests_timeout=15,
            enable_resource_blocking=True,
        )
        scraper = IntelligentFallbackScraper(config)

        # Test with a reliable endpoint
        result = await scraper.scrape_url("https://httpbin.org/html")

        assert result.success is True
        assert result.strategy_used in [
            FallbackStrategy.PLAYWRIGHT_OPTIMIZED,
            FallbackStrategy.REQUESTS_FALLBACK,
        ]
        assert result.attempts >= 1

    @pytest.mark.asyncio
    @pytest.mark.integration
    async def test_rate_limiting_and_retry_behavior(self):
        """Test robust scraping behavior."""
        config = FallbackConfig(
            max_retries=3,
            playwright_timeout=10,
        )
        scraper = IntelligentFallbackScraper(config)

        result = await scraper.scrape_url("https://httpbin.org/html")

        # Should succeed with any strategy
        assert result.success is True
        assert result.strategy_used in [
            FallbackStrategy.PLAYWRIGHT_OPTIMIZED,
            FallbackStrategy.REQUESTS_FALLBACK,
        ]

    @pytest.mark.asyncio
    @pytest.mark.integration
    async def test_memory_efficiency_large_content(self):
        """Test memory efficiency with content processing."""
        config = FallbackConfig(
            enable_resource_blocking=True,
            blocked_resource_types=["image", "stylesheet", "font", "media", "script"],
        )
        scraper = IntelligentFallbackScraper(config)

        result = await scraper.scrape_url("https://httpbin.org/html")

        assert result.success is True
        assert result.content is not None

        # Verify content was cleaned (no scripts, styles, etc.)
        assert "<script>" not in result.content
        assert "<style>" not in result.content
